{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI2ZKbMv7Jpl"
      },
      "source": [
        "\n",
        "# **Assignment 1:MLP for Image Classification:Connectionist AI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s00pplaljlza"
      },
      "source": [
        "Imports and Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "X38do2iL6uh1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1l0Dy1YisPt"
      },
      "source": [
        "Extracting labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_0zLIMI7wkf",
        "outputId": "d932bb03-d803-4aeb-dad9-9c24f707e030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels:[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "total_labels = len(np.unique(y_train))\n",
        "print(f\"labels:{np.unique(y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFF2N7ByiwGQ"
      },
      "source": [
        "One-Hot encoding for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "scXEerKy8P9H"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCykhRkci1s5"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTpl09S_8xDl",
        "outputId": "4ca859ba-7ed5-4329-83d7-b0647c582bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train:(60000, 784)\n",
            "x_test:(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "input_size = x_train.shape[1]**2\n",
        "x_train = np.reshape(x_train, (-1,input_size))\n",
        "x_train = x_train.astype('float32') / 255\n",
        "\n",
        "x_test = np.reshape(x_test, (-1,input_size))\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "print(f\"x_train:{x_train.shape}\")\n",
        "print(f\"x_test:{x_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hFPR9Ffi6SZ"
      },
      "source": [
        "Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "GmaoqTU0i8Ml"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "hidden_units = 256\n",
        "dropout = 0.35"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LiesU5Ei-uJ"
      },
      "source": [
        "The Traditional MLP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmbfwJp1v27b",
        "outputId": "748c022f-a993-41b2-f2af-86f9b2f0617d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_190\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_358 (Dense)           (None, 256)               200960    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_175 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_359 (Dense)           (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_176 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_360 (Dense)           (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269322 (1.03 MB)\n",
            "Trainable params: 269322 (1.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(hidden_units, input_dim=input_size))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Dense(hidden_units))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Dense(total_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f7ipcrLjD0I"
      },
      "source": [
        "MLP Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrRcuRIPwnrH",
        "outputId": "e8e4b2c2-1a0c-47bd-9eb7-f6ad00c7adf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 7s 6ms/step - loss: 0.3203 - accuracy: 0.9038\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1529 - accuracy: 0.9537\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1183 - accuracy: 0.9636\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0986 - accuracy: 0.9702\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9722\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0833 - accuracy: 0.9739\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0707 - accuracy: 0.9775\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0675 - accuracy: 0.9786\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0642 - accuracy: 0.9802\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0591 - accuracy: 0.9812\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bf6ceaca3b0>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO5klGnKjLxo"
      },
      "source": [
        "MLP model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLVVL6Svw8AF",
        "outputId": "0b96c491-eaaa-4f89-e64d-0d05f6b98566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.2%\n"
          ]
        }
      ],
      "source": [
        "_, acc = model.evaluate(x_test,\n",
        "                        y_test,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=0)\n",
        "print(f\"Accuracy: {100.0 * acc}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GqthE0rjPnx"
      },
      "source": [
        "---\n",
        "## Traditional MLP Accuracy: 98.2%\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSB9-8Yl4fpZ"
      },
      "source": [
        "## MLP-Mixer model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QHRUnmlcgsq"
      },
      "source": [
        "Arguments(HyperParameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W354gGiNLN6"
      },
      "outputs": [],
      "source": [
        "patch_size = 4\n",
        "num_patches = (28 // patch_size) ** 2\n",
        "# print( (input_size // patch_size) ** 2)\n",
        "hidden_units=64\n",
        "learning_speed=0.05\n",
        "# print(num_patches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a42YdTNUcxbF"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64L_A84WcvWm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LayerNormalization, Layer, Input, GlobalAveragePooling1D, Dropout\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow import transpose,reshape,shape\n",
        "from tensorflow.image import extract_patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zmoS-P5hbVj"
      },
      "source": [
        "The Mixer Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zkwl5hpT4iiS"
      },
      "outputs": [],
      "source": [
        "class MixerLayer(Layer):\n",
        "    def __init__(self, num_patches, hidden_units, dropout, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.mlp1 = Sequential(\n",
        "            [\n",
        "                Dense(units=num_patches, activation=\"gelu\"),\n",
        "                Dense(units=num_patches),\n",
        "                Dropout(rate=dropout),\n",
        "            ]\n",
        "        )\n",
        "        self.mlp2 = Sequential(\n",
        "            [\n",
        "                Dense(units=num_patches, activation=\"gelu\"),\n",
        "                Dense(units=hidden_units),\n",
        "                Dropout(rate=dropout),\n",
        "            ]\n",
        "        )\n",
        "        self.normalize = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        return super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.normalize(inputs)\n",
        "        x_channels = transpose(x, perm=(0, 2, 1))\n",
        "        mlp1_outputs = self.mlp1(x_channels)\n",
        "        mlp1_outputs = transpose(mlp1_outputs, perm=(0, 2, 1))\n",
        "        x = mlp1_outputs + inputs\n",
        "        x_patches = self.normalize(x)\n",
        "        mlp2_outputs = self.mlp2(x_patches)\n",
        "        x = x + mlp2_outputs\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUKqNNsUhe1x"
      },
      "source": [
        "The Patch extraction Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7mgVVr8Qnm6"
      },
      "outputs": [],
      "source": [
        "class PatchesLayer(Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, x):\n",
        "        patches = extract_patches(images=x, sizes=[1, self.patch_size, self.patch_size, 1], strides=[1, self.patch_size, self.patch_size, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
        "        batch_size = shape(patches)[0]\n",
        "        num_patches = shape(patches)[1] * shape(patches)[2]\n",
        "        patch_dim =shape(patches)[3]\n",
        "        output = reshape(patches, (batch_size, num_patches, patch_dim))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IJIxFY5bm3w"
      },
      "source": [
        "Model Maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "I3OtbR-TOn2E"
      },
      "outputs": [],
      "source": [
        "def model_maker(blocks):\n",
        "    #The input layer\n",
        "    inputs = Input(shape=(28,28,1))\n",
        "    #The patch extraction layer\n",
        "    patches = PatchesLayer(patch_size)(inputs)\n",
        "    x = Dense(units=hidden_units)(patches)\n",
        "    x = blocks(x)\n",
        "    #The average pooling layer\n",
        "    condensed_input = GlobalAveragePooling1D()(x)\n",
        "    condensed_input = Dropout(rate=dropout)(condensed_input)\n",
        "    #The Output layer\n",
        "    logits = Dense(total_labels,activation='softmax')(condensed_input)\n",
        "    return Model(inputs=inputs, outputs=logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg0-V1qBaTOb"
      },
      "source": [
        "Building of the model using the Patch and"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "XgZGEHczRRWC"
      },
      "outputs": [],
      "source": [
        "mixer_blocks = Sequential(\n",
        "    [MixerLayer(num_patches, hidden_units, dropout) for _ in range(4)]\n",
        ")\n",
        "learning_rate = 0.005\n",
        "mixer_model = model_maker(mixer_blocks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-xkobYxaMHQ"
      },
      "source": [
        "Loading of dataset for the Mixer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJxaRpwsVVlj"
      },
      "outputs": [],
      "source": [
        "(x_train_res, y_train_res), (x_test_res, y_test_res) = mnist.load_data()\n",
        "x_train_res = x_train_res.reshape((-1, 28, 28, 1))\n",
        "x_test_res = x_test_res.reshape((-1, 28, 28, 1))\n",
        "x_train_res = x_train_res.astype('float32') / 255\n",
        "x_test_res = x_test_res.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXveimD7Z8n5",
        "outputId": "761869b9-c509-4ea3-8d84-894a66ed30e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " patches_16 (Patches)        (None, 49, 16)            0         \n",
            "                                                                 \n",
            " dense_320 (Dense)           (None, 49, 64)            1088      \n",
            "                                                                 \n",
            " sequential_171 (Sequential  (None, 49, 64)            45652     \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling1d_2  (None, 64)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dropout_156 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_321 (Dense)           (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47390 (185.12 KB)\n",
            "Trainable params: 47390 (185.12 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mixer_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f6Y5fMwaIF4"
      },
      "source": [
        "Mixer Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBACozGY5Mua",
        "outputId": "a20ff03e-68ce-4a71-968d-0b4cf9f7adb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 27s 19ms/step - loss: 0.6319 - accuracy: 0.7923\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 0.2753 - accuracy: 0.9158\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.2051 - accuracy: 0.9384\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.1681 - accuracy: 0.9492\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.1494 - accuracy: 0.9548\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 0.1337 - accuracy: 0.9593\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.1203 - accuracy: 0.9627\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 0.1141 - accuracy: 0.9656\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 0.1053 - accuracy: 0.9677\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 21s 22ms/step - loss: 0.0996 - accuracy: 0.9697\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bf69c150760>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mixer_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "mixer_model.fit(x_train_res, y_train_res, epochs=10, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsj_Iu5haC76"
      },
      "source": [
        "Mixer Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1v2qzf05gJY",
        "outputId": "b07f97a8-a20d-4aee-e9e1-a0404a78c3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mixer MLP Accuracy: 97.4%\n"
          ]
        }
      ],
      "source": [
        "_, acc_mixer = mixer_model.evaluate(x_test_res, y_test_res, batch_size=64, verbose=0)\n",
        "print(f\"Mixer MLP Accuracy: {100*acc}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXASPmTFjsRh"
      },
      "source": [
        "---\n",
        "## Mixer-MLP accuracy: 97.4%\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRYFQwsbjy6o"
      },
      "source": [
        "Looking at the models from various perspectives it is clear that the Traditional MLP outperforms the MLP mixer model by a difference of 0.9%.\n",
        "The reasons being the overall complexity of the task and the complexity of the models: where Traditional MLP is a much simpler model and would perform good on simple tasks the Mixer model is not designed for such low level tasks. And would thus beat the Traditional model on other tasks. Also it can be pretrained to further diversify it's usage and improve overall accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkHQdoF47lpJ"
      },
      "source": [
        "##References\n",
        "- https://www.analyticsvidhya.com/blog/2020/12/mlp-multilayer-perceptron-simple-overview/\n",
        "- https://www.v7labs.com/blog/neural-networks-activation-functions\n",
        "- https://www.baeldung.com/cs/learning-rate-batch-size#:~:text=Batch%20size%20defines%20the%20number,training%20set%20in%20one%20epoch.\n",
        "- https://arxiv.org/abs/2105.03404v2\n",
        "- https://sh-tsang.medium.com/review-resmlp-feedforward-networks-for-image-classification-with-data-efficient-training-4eeb1eb5efa6\n",
        "- https://stats.stackexchange.com/questions/162988/why-sigmoid-function-instead-of-anything-else/318209#318209"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
